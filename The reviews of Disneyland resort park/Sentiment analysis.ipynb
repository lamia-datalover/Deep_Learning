{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow & Pathlib librairies\n",
    "import tensorflow as tf \n",
    "import pathlib \n",
    "import pandas as pd \n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c75c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset with Pandas \n",
    "dataset = pd.read_csv(\"https://go.aws/314bBDq\", error_bad_lines=False, encoding=\"utf-8\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only french reviews\n",
    "french_reviews = dataset[dataset.review_lang == \"french\"]\n",
    "french_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77184a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the columns we're interested in \n",
    "french_reviews = french_reviews[[\"review\", \"stars\"]]\n",
    "french_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download fr_core_news_md -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ad06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spacy and french initialisation\n",
    "import fr_core_news_md\n",
    "nlp = fr_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stop words \n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning our texts in order to prepare them for training\n",
    "french_reviews[\"review_clean\"] = french_reviews[\"review\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \" or ch==\"'\"))\n",
    "french_reviews[\"review_clean\"] = french_reviews[\"review_clean\"].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
    "french_reviews[\"review_clean\"] = french_reviews[\"review_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) and (token.text not in STOP_WORDS)]))\n",
    "\n",
    "french_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9d4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_reviews = pd.read_csv(\"https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Deep+Learning/sentiment-analysis/french_reviews_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = french_reviews.review_clean.apply(lambda x: type(x)==str)\n",
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ff815",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_reviews = french_reviews.loc[mask,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cefcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciating the tokenizer, make sure you set it up to keep only the 1000 most common words \n",
    "import numpy as np\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000, oov_token=\"out_of_vocab\") # instanciate the tokenizer\n",
    "tokenizer.fit_on_texts(french_reviews.review_clean)\n",
    "french_reviews[\"review_encoded\"] = tokenizer.texts_to_sequences(french_reviews.review_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = tf.data.Dataset.from_tensor_slices((french_reviews.review_encoded, french_reviews.stars.values-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6431eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_pad = tf.keras.preprocessing.sequence.pad_sequences(french_reviews.review_encoded, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d738f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(reviews_pad,french_reviews.stars, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac105ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\n",
    "val = tf.data.Dataset.from_tensor_slices((xval, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = train.shuffle(len(train)).batch(64)\n",
    "val_batch = val.shuffle(len(val)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, star in train_batch.take(1):\n",
    "  print(review, star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4de430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a model in order to train an embedding\n",
    "vocab_size = tokenizer.num_words\n",
    "model = tf.keras.Sequential([\n",
    "                  # Couche d'Input Word Embedding           \n",
    "                  tf.keras.layers.Embedding(vocab_size+1, 8, input_shape=[review.shape[1],],name=\"embedding\"),\n",
    "                  # Gobal average pooling\n",
    "                  tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "                  # Couche Dense classique\n",
    "                  tf.keras.layers.Dense(16, activation='relu'),\n",
    "\n",
    "                  # Couche de sortie avec le nombre de neurones en sortie Ã©gale au nombre de classe avec fonction softmax\n",
    "                  tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0046154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_batch, \n",
    "                    epochs=20, \n",
    "                    validation_data=val_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization of the training process on the loss function \n",
    "plt.plot(history.history[\"loss\"], color=\"b\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"r\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of accuracy training \n",
    "plt.plot(history.history[\"mean_absolute_error\"], color=\"b\")\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"], color=\"r\")\n",
    "plt.ylabel(\"mean_absolute_error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2515b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [value for value in tokenizer.index_word.values()]\n",
    "vocab = vocab[:1000]\n",
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "\n",
    "log_dir = \"/content/logs/embed\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "out_v = io.open(log_dir+\"/vectors.tsv\", 'w', encoding='utf-8')\n",
    "out_m = io.open(log_dir+\"/metadata.tsv\", 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f6888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
